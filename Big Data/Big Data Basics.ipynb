{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. What is Big Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big data are collection of large and complex data sets that are difficult to process using on hand database system \n",
    "tools or traditional data processing applications.\n",
    "\n",
    "5 V's of Big data\n",
    "\n",
    "- Volume - large amount of data that is being generated.\n",
    "- variety - Different kinds of data getting generated from different sources.\n",
    "- velocity - The rate at which data is being generated\n",
    "- value - Extracting meaningful infomation from the large data\n",
    "- veracity - The inconsistencies and uncertainities present in the data that needs to be taken care of.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is Hadoop ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop is a framework that allows us to store and process large data sets in parallel and distributed manner.\n",
    "\n",
    "Hadoop is basically a solution for:\n",
    "  1. Storing exponentially growing large data sets.\n",
    "  2. Processing data having complex structure\n",
    "  3. processing data at a fast rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What is Hadoop Distributed File System (HDFS) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides scalable and reliable data storage. It is designed to hold very large amount of data and provide high throughput access to the information. It allows to dump any kind of data across the cluster and is called the **storage unit of hadoop**. It divides the input data into smaller chunks and stores it across the cluster.  \n",
    "\n",
    "It has 2 components. \n",
    "\n",
    "- **Namenode** - The main node that contains metadata about the data stored.\n",
    "- **Datanodes** - The actual data stored which are commodity hardware in the distribued system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. What is mapreduce ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It allows parallel processing of data that is stored across the HDFS. Allows to process the data locally i.e each node works with a part of data that is store on it. In simpler terms the logic is basically sent to each data node to process it and the chunk results are then return to the main node which minimizes network conjestion and allows faster processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Why do we need cloud Services ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Major advantage of cloud is the __ability to access the data and application from anywhere__ around the globe. It is also very __cost effective__ which allows the company to pay only for the services or storage space they want for their business. It also provides __security__ of its infrastructure and __flexibility__ in terms of databases, programming langauges and operating systems. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
